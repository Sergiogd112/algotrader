{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Symbol import Symbol\n",
    "from Merger import Merger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import json\n",
    "import gc\n",
    "import os\n",
    "import pickle as pk\n",
    "from multiprocessing import Pool,cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading\n",
      "./data/ ['Wed_Apr_15_18:49:52_2020.pkl', 'Wed_Apr_8_18_27_23_2020.pkl', 'Thu_Apr_16_18:52:58_2020.pkl', 'Thu_Apr_9_18:30:41_2020.pkl', 'Sun_Mar_15_17_18_41_2020.pkl', 'Fri_Apr_10_18:33:44_2020.pkl', 'Sat_Apr_11_18:36:46_2020.pkl', 'Sun_Apr_5_01_08_13_2020.pkl', 'Sun_Apr_12_18:39:46_2020.pkl', 'Mon_Apr_20_19:05:21_2020.pkl', 'Sat_Apr_18_18:59:09_2020.pkl', 'Sun_Apr_19_19:02:11_2020.pkl', 'Fri_Mar_27_10_58_08_2020.pkl', 'Mon_Apr_13_18:42:48_2020.pkl', 'Wed_Apr_8_17_42_59_2020.pkl', 'Tue_Apr_14_18:45:49_2020.pkl', 'Fri_Apr_17_18:56:04_2020.pkl', 'Mon_Apr_6_11_44_48_2020.pkl']\n",
      "32.42848253250122\n",
      "merging tickers\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "57.40202617645264\n"
     ]
    }
   ],
   "source": [
    "df=Merger.gen_df('./data/')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path='./data/'\n",
    "files=[y for y in os.listdir(path)  if '.pkl' in y]\n",
    "for n,file in enumerate(files):\n",
    "    try:\n",
    "        pk.load(open(path+file,'rb'))\n",
    "    except Exception as e:\n",
    "        print(n,file)\n",
    "        a=e\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self,money,l,inshape=(73*3)):\n",
    "        model=Sequential()\n",
    "        model.add(Dense(inshape,inshape=inshape))\n",
    "        model.add(Dense((7,2)))\n",
    "        self.l=l\n",
    "        self.money=[0]*(l-1)+[money]\n",
    "        self.inshape=inshape\n",
    "        self.wallet=[0.0]*8\n",
    "        self.wallethist=[self.wallet]*10\n",
    "        self.hist=[]\n",
    "    def update_money(self,money):\n",
    "        self.money=[money]+self.money[:-2]\n",
    "    def gen_df(self,arr):\n",
    "        df_lstm=[row+[m]+[w] for row,m,w in zip(arr,self.money,self.wallethist)]\n",
    "        return df_lstm\n",
    "    def gen_df_player(self, lstm_pred,current,prev):\n",
    "        return np.array(lstm_pred+current+prev)\n",
    "    def act(self,arr):\n",
    "        df=self.gen_df(arr)\n",
    "        act=np.array(self.model.predict(df))\n",
    "        act=[act[:8],act[-8:]]\n",
    "        self.hist+=[df,pred]  \n",
    "        return act\n",
    "    def calc_payment(self,cost,pred):\n",
    "        to_pay=self.money*sum(pred[0])\n",
    "        to_sell=sum([stock*x*w for stock,x,w in zip(arr,pred[1],self.wallet)])\n",
    "        \n",
    "    def step(self,arr):\n",
    "        pred=self.predict(arr)\n",
    "        cost=arr[-1]\n",
    "        self.update_money(self.money[-1]-self.money[-1]*sum(pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self,inshape=(10,73)):\n",
    "        self.inshape=inshape\n",
    "        self.model=Predictor.gen_model(inshape)\n",
    "        \n",
    "    def gen_model(inshape):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(inshape[1],input_shape=inshape,activation='tanh',return_sequences=True))\n",
    "        model.add(LSTM(128,activation='sigmoid'))\n",
    "        model.add(Dense(128,activation='sigmoid'))\n",
    "        model.add(Dense(inshape[1]))\n",
    "        model.add(Dense(inshape[1]))\n",
    "        return model\n",
    "    def predict(self,arr):\n",
    "        return self.model.predict(arr)\n",
    "    def reset(self):\n",
    "        self.model=Predictor.gen_model(self.inshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,pops,topn=None,new=None,money):\n",
    "        if(topn==None):\n",
    "            topn=int(pops*0.1)\n",
    "        if (new==None):\n",
    "            new=int(pops*0.05)\n",
    "        print('generating pop')\n",
    "        self.money=money\n",
    "        self.currentgen=Generation(pops,money)\n",
    "        self.pop_hist=[self.currentpop]\n",
    "        print('seting params')\n",
    "        self.topn=topn\n",
    "        self.new=new\n",
    "        gc.collect()\n",
    "    def gen_1_df(self,df,money,length):\n",
    "        arr=df.values[:10]\n",
    "        return [row+[money] for row in arr]\n",
    "\n",
    "    def start(self,df,money,generations=100):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generation:\n",
    "    def __init__(self,pops,money):\n",
    "        self.pops=pops\n",
    "        self.pop=[Model() for x in range(pops)]\n",
    "    def run(self,df):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test=[x for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[test[:5],test[-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Just your regular densely-connected NN layer.\n",
       "\n",
       "`Dense` implements the operation:\n",
       "`output = activation(dot(input, kernel) + bias)`\n",
       "where `activation` is the element-wise activation function\n",
       "passed as the `activation` argument, `kernel` is a weights matrix\n",
       "created by the layer, and `bias` is a bias vector created by the layer\n",
       "(only applicable if `use_bias` is `True`).\n",
       "\n",
       "Note: if the input to the layer has a rank greater than 2, then\n",
       "it is flattened prior to the initial dot product with `kernel`.\n",
       "\n",
       "# Example\n",
       "\n",
       "```python\n",
       "    # as first layer in a sequential model:\n",
       "    model = Sequential()\n",
       "    model.add(Dense(32, input_shape=(16,)))\n",
       "    # now the model will take as input arrays of shape (*, 16)\n",
       "    # and output arrays of shape (*, 32)\n",
       "\n",
       "    # after the first layer, you don't need to specify\n",
       "    # the size of the input anymore:\n",
       "    model.add(Dense(32))\n",
       "```\n",
       "\n",
       "# Arguments\n",
       "    units: Positive integer, dimensionality of the output space.\n",
       "    activation: Activation function to use\n",
       "        (see [activations](../activations.md)).\n",
       "        If you don't specify anything, no activation is applied\n",
       "        (ie. \"linear\" activation: `a(x) = x`).\n",
       "    use_bias: Boolean, whether the layer uses a bias vector.\n",
       "    kernel_initializer: Initializer for the `kernel` weights matrix\n",
       "        (see [initializers](../initializers.md)).\n",
       "    bias_initializer: Initializer for the bias vector\n",
       "        (see [initializers](../initializers.md)).\n",
       "    kernel_regularizer: Regularizer function applied to\n",
       "        the `kernel` weights matrix\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    bias_regularizer: Regularizer function applied to the bias vector\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    activity_regularizer: Regularizer function applied to\n",
       "        the output of the layer (its \"activation\").\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    kernel_constraint: Constraint function applied to\n",
       "        the `kernel` weights matrix\n",
       "        (see [constraints](../constraints.md)).\n",
       "    bias_constraint: Constraint function applied to the bias vector\n",
       "        (see [constraints](../constraints.md)).\n",
       "\n",
       "# Input shape\n",
       "    nD tensor with shape: `(batch_size, ..., input_dim)`.\n",
       "    The most common situation would be\n",
       "    a 2D input with shape `(batch_size, input_dim)`.\n",
       "\n",
       "# Output shape\n",
       "    nD tensor with shape: `(batch_size, ..., units)`.\n",
       "    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
       "    the output would have shape `(batch_size, units)`.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/keras/layers/core.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[test[:5],test[-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
